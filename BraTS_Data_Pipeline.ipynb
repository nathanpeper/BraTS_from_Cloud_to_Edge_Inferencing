{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20df4cd8-9e05-48f8-9cbc-de76f1c9545e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo $CONDA_PREFIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e670606-20fe-42a1-a0cb-363d7460c4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras as K\n",
    "\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#import warnings\n",
    "#warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7b2a4f-0e82-49f9-b25d-ae1ad0b612c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mkl_enabled_flag():\n",
    "\n",
    "    mkl_enabled = False\n",
    "    major_version = int(tf.__version__.split(\".\")[0])\n",
    "    minor_version = int(tf.__version__.split(\".\")[1])\n",
    "    if major_version >= 2:\n",
    "        if minor_version < 5:\n",
    "            from tensorflow.python import _pywrap_util_port\n",
    "        elif minor_version >= 9:\n",
    "\n",
    "            from tensorflow.python.util import _pywrap_util_port\n",
    "            onednn_enabled = int(os.environ.get('TF_ENABLE_ONEDNN_OPTS', '1'))\n",
    "\n",
    "        else:\n",
    "            from tensorflow.python.util import _pywrap_util_port\n",
    "            onednn_enabled = int(os.environ.get('TF_ENABLE_ONEDNN_OPTS', '0'))\n",
    "        mkl_enabled = _pywrap_util_port.IsMklEnabled() or (onednn_enabled == 1)\n",
    "    else:\n",
    "        mkl_enabled = tf.pywrap_tensorflow.IsMklEnabled()\n",
    "    return mkl_enabled\n",
    "\n",
    "print (\"We are using Tensorflow version\", tf.__version__)\n",
    "print(\"MKL enabled :\", get_mkl_enabled_flag())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbaf324-2454-493d-8158-718a08cdd582",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2bf7b5-e775-4989-be1b-a861f82c64b9",
   "metadata": {},
   "source": [
    "## Define the settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5121d494-efcf-484a-899d-69502fda4658",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH=\"/home/ubuntu/unet/data/Task01_BrainTumour/\"\n",
    "\n",
    "TRAIN_TEST_SPLIT = 0.80\n",
    "VALIDATE_TEST_SPLIT = 0.50\n",
    "\n",
    "BATCH_SIZE_TRAIN = 8\n",
    "BATCH_SIZE_VALIDATE = 4\n",
    "BATCH_SIZE_TEST = 1\n",
    "\n",
    "TILE_HEIGHT = 128\n",
    "TILE_WIDTH = 128\n",
    "TILE_DEPTH = 128\n",
    "NUMBER_INPUT_CHANNELS = 1\n",
    "\n",
    "CROP_DIM = (128,128,128,1)\n",
    "#CROP_DIM = (144,144,144,1)\n",
    "\n",
    "NUMBER_OUTPUT_CLASSES = 1\n",
    "\n",
    "RANDOM_SEED = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9e7301-0e02-4751-9dc1-66648d87266d",
   "metadata": {},
   "source": [
    "## Define a data loader\n",
    "\n",
    "We'll use `tf.data` to define a way to load the BraTS dataset at runtime whenever a new batch of 3D images and masks are requested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef617c2-f718-48f1-80e4-6cd65c974884",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetGenerator:\n",
    "        \n",
    "    def __init__(self, \n",
    "                 data_path = DATA_PATH,\n",
    "                 train_test_split = TRAIN_TEST_SPLIT,\n",
    "                 validate_test_split = VALIDATE_TEST_SPLIT,\n",
    "                 batch_size_train = BATCH_SIZE_TRAIN,\n",
    "                 batch_size_validate = BATCH_SIZE_VALIDATE,\n",
    "                 batch_size_test = BATCH_SIZE_TEST,\n",
    "                 crop_dim = CROP_DIM,\n",
    "                 number_output_classes = NUMBER_OUTPUT_CLASSES,\n",
    "                 random_seed = RANDOM_SEED\n",
    "                ):\n",
    "        \n",
    "        self.data_path = data_path\n",
    "        self.train_test_split = train_test_split\n",
    "        self.validate_test_split = validate_test_split\n",
    "        self.batch_size_train = batch_size_train\n",
    "        self.batch_size_validate = batch_size_validate\n",
    "        self.batch_size_test = batch_size_test\n",
    "        self.crop_dim = crop_dim\n",
    "        self.number_output_classes = number_output_classes\n",
    "        self.random_seed = random_seed\n",
    "        \n",
    "        self.create_file_list()\n",
    "        \n",
    "#        self.ds_train, self.ds_val, self.ds_test = self.get_dataset()\n",
    "\n",
    "\n",
    "    def create_file_list(self):\n",
    "        \"\"\"\n",
    "        Get list of the files from the BraTS raw data\n",
    "        Split into training and testing sets.\n",
    "        \"\"\"\n",
    "        import os\n",
    "        import json\n",
    "        \n",
    "        json_filename = os.path.join(self.data_path, \"dataset.json\")\n",
    "\n",
    "        try:\n",
    "            with open(json_filename, \"r\") as fp:\n",
    "                experiment_data = json.load(fp)\n",
    "        except IOError as e:\n",
    "            print(\"File {} doesn't exist. It should be part of the \"\n",
    "                  \"Decathlon directory\".format(json_filename))\n",
    "\n",
    "        self.output_channels = experiment_data[\"labels\"]\n",
    "        self.input_channels = experiment_data[\"modality\"]\n",
    "        self.description = experiment_data[\"description\"]\n",
    "        self.name = experiment_data[\"name\"]\n",
    "        self.release = experiment_data[\"release\"]\n",
    "        self.license = experiment_data[\"licence\"]\n",
    "        self.reference = experiment_data[\"reference\"]\n",
    "        self.tensor_image_size = experiment_data[\"tensorImageSize\"]\n",
    "        self.num_files = experiment_data[\"numTraining\"]\n",
    "        \n",
    "        \"\"\"\n",
    "        Create a dictionary of tuples with image filename and label filename\n",
    "        \"\"\"\n",
    "        self.filenames = {}\n",
    "        for idx in range(self.num_files):\n",
    "            self.filenames[idx] = [os.path.join(self.data_path,\n",
    "                                              experiment_data[\"training\"][idx][\"image\"]),\n",
    "                                    os.path.join(self.data_path,\n",
    "                                              experiment_data[\"training\"][idx][\"label\"])]\n",
    "            \n",
    "        \n",
    "    def print_info(self):\n",
    "        \"\"\"\n",
    "        Print the dataset information\n",
    "        \"\"\"\n",
    "\n",
    "        print(\"=\"*30)\n",
    "        print(\"Dataset name:        \", self.name)\n",
    "        print(\"Dataset description: \", self.description)\n",
    "        print(\"Tensor image size:   \", self.tensor_image_size)\n",
    "        print(\"Dataset release:     \", self.release)\n",
    "        print(\"Dataset reference:   \", self.reference)\n",
    "        print(\"Input channels:      \", self.input_channels)\n",
    "        print(\"Output labels:       \", self.output_channels)\n",
    "        print(\"Dataset license:     \", self.license)\n",
    "        print(\"=\"*30)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ea5fc9-d3c7-4e3e-b474-e5e5285fd2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "brats_datafiles = DatasetGenerator(DATA_PATH)\n",
    "brats_datafiles.print_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eef7cf4-2662-42ec-a8b6-2ec5a11dd922",
   "metadata": {},
   "source": [
    "## Data preprocessing\n",
    "\n",
    "Here we preprocess the 3D MRI scans. We'll normalize the images, crop the images, and do random flips/rotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30764cc3-21b7-4f63-9546-36d188240f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def z_normalize_img(img):\n",
    "    \"\"\"\n",
    "    Normalize the image so that the mean value for each image\n",
    "    is 0 and the standard deviation is 1.\n",
    "    \"\"\"\n",
    "    for channel in range(img.shape[-1]):\n",
    "\n",
    "        img_temp = img[..., channel]\n",
    "        img_temp = (img_temp - np.mean(img_temp)) / np.std(img_temp)\n",
    "\n",
    "        img[..., channel] = img_temp\n",
    "\n",
    "    return img\n",
    "    \n",
    "def crop(img, msk, randomize):\n",
    "        \"\"\"\n",
    "        Randomly crop the image and mask\n",
    "        \"\"\"\n",
    "\n",
    "        slices = []\n",
    "        \n",
    "        # Do we randomize?\n",
    "        is_random = randomize and np.random.rand() > 0.5\n",
    "\n",
    "        for idx in range(len(img.shape)-1):  # Go through each dimension\n",
    "\n",
    "            crop_len = brats_datafiles.crop_dim[idx]\n",
    "            img_len = img.shape[idx]\n",
    "\n",
    "            start = (img_len-crop_len)//2\n",
    "\n",
    "            ratio_crop = 0.20  # Crop up this this % of pixels for offset\n",
    "            # Number of pixels to offset crop in this dimension\n",
    "            offset = int(np.floor(start*ratio_crop))\n",
    "\n",
    "            if offset > 0:\n",
    "                if is_random:\n",
    "                    start += np.random.choice(range(-offset, offset))\n",
    "                    if ((start + crop_len) > img_len):  # Don't fall off the image\n",
    "                        start = (img_len-crop_len)//2\n",
    "            else:\n",
    "                start = 0\n",
    "\n",
    "            slices.append(slice(start, start+crop_len))\n",
    "\n",
    "        return img[tuple(slices)], msk[tuple(slices)]\n",
    "    \n",
    "def augment_data(img, msk, crop_dim):\n",
    "    \"\"\"\n",
    "    Data augmentation\n",
    "    Flip image and mask. Rotate image and mask.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Determine if axes are equal and can be rotated\n",
    "    # If the axes aren't equal then we can't rotate them.\n",
    "    equal_dim_axis = []\n",
    "    for idx in range(0, len(crop_dim)):\n",
    "        for jdx in range(idx+1, len(crop_dim)):\n",
    "            if crop_dim[idx] == crop_dim[jdx]:\n",
    "                equal_dim_axis.append([idx, jdx])  # Valid rotation axes\n",
    "    dim_to_rotate = equal_dim_axis\n",
    "\n",
    "    if np.random.rand() > 0.5:\n",
    "        # Random 0,1 (axes to flip)\n",
    "        ax = np.random.choice(np.arange(len(crop_dim)-1))\n",
    "        img = np.flip(img, ax)\n",
    "        msk = np.flip(msk, ax)\n",
    "\n",
    "    elif (len(dim_to_rotate) > 0) and (np.random.rand() > 0.5):\n",
    "        rot = np.random.choice([1, 2, 3])  # 90, 180, or 270 degrees\n",
    "\n",
    "        # This will choose the axes to rotate\n",
    "        # Axes must be equal in size\n",
    "        random_axis = dim_to_rotate[np.random.choice(len(dim_to_rotate))]\n",
    "        \n",
    "        img = np.rot90(img, rot, axes=random_axis)  # Rotate axes 0 and 1\n",
    "        msk = np.rot90(msk, rot, axes=random_axis)  # Rotate axes 0 and 1\n",
    "\n",
    "    return img, msk\n",
    "    \n",
    "def read_nifti_file(idx, crop_dim, randomize=False):\n",
    "    \"\"\"\n",
    "    Read Nifti file\n",
    "    \"\"\"\n",
    "    \n",
    "    idx = idx.numpy()\n",
    "    img_file = brats_datafiles.filenames[idx][0]\n",
    "    msk_file = brats_datafiles.filenames[idx][1]\n",
    "    \n",
    "    img = np.array(nib.load(img_file).dataobj)\n",
    "    \n",
    "    img = np.rot90(img[...,[0]]) # Just take the FLAIR channel (0)\n",
    "    \n",
    "    msk = np.rot90(np.array(nib.load(msk_file).dataobj))\n",
    "\n",
    "    \"\"\"\n",
    "    \"labels\": {\n",
    "         \"0\": \"background\",\n",
    "         \"1\": \"edema\",\n",
    "         \"2\": \"non-enhancing tumor\",\n",
    "         \"3\": \"enhancing tumour\"}\n",
    "     \"\"\"\n",
    "    # Combine all masks but background\n",
    "    if brats_datafiles.number_output_classes == 1:\n",
    "        msk[msk > 0] = 1.0\n",
    "        msk = np.expand_dims(msk, -1)\n",
    "    else:\n",
    "        msk_temp = np.zeros(list(msk.shape) + [brats_datafiles.number_output_classes])\n",
    "        for channel in range(brats_datafiles.number_output_classes):\n",
    "            msk_temp[msk == channel, channel] = 1.0\n",
    "        msk = msk_temp\n",
    "    \n",
    "#    imgFilename = (os.path.basename(brats_datafiles.filenames[idx][0])).split(\".nii.gz\")[0]\n",
    "    \n",
    "    # Crop\n",
    "    img, msk = crop(img, msk, randomize)\n",
    "    \n",
    "    # Normalize\n",
    "    img = z_normalize_img(img)\n",
    "    \n",
    "    # Randomly rotate\n",
    "    if randomize:\n",
    "        img, msk = augment_data(img, msk, crop_dim)\n",
    "    \n",
    "    return img, msk\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d790da-1a1c-4127-80ad-892157d5fbe0",
   "metadata": {},
   "source": [
    "## tf.data\n",
    "\n",
    "Define the training, testing, and validation data loaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e76247d-7b6f-4bb5-b39c-6a1b049dba54",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_files = brats_datafiles.num_files\n",
    "num_train = int(num_files * brats_datafiles.train_test_split)\n",
    "num_val_test = num_files - num_train\n",
    "\n",
    "ds = tf.data.Dataset.range(num_files).shuffle(num_files, brats_datafiles.random_seed) # Shuffle the dataset\n",
    "\n",
    "ds_train = ds.take(num_train)\n",
    "ds_val_test = ds.skip(num_train)\n",
    "ds_val = ds_val_test.take(int(num_val_test * brats_datafiles.validate_test_split))\n",
    "ds_test = ds_val_test.skip(int(num_val_test * brats_datafiles.validate_test_split))\n",
    "\n",
    "ds_train = ds_train.map(lambda x: tf.py_function(read_nifti_file, [x, brats_datafiles.crop_dim, True], [tf.float32, tf.float32]), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_val = ds_val.map(lambda x: tf.py_function(read_nifti_file, [x, brats_datafiles.crop_dim, False], [tf.float32, tf.float32]), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_test = ds_test.map(lambda x: tf.py_function(read_nifti_file, [x, brats_datafiles.crop_dim, False], [tf.float32, tf.float32]), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "ds_train = ds_train.repeat()\n",
    "ds_train = ds_train.batch(brats_datafiles.batch_size_train)\n",
    "ds_train = ds_train.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "ds_val = ds_val.batch(brats_datafiles.batch_size_validate)\n",
    "ds_val = ds_val.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "ds_test = ds_test.batch(brats_datafiles.batch_size_test)\n",
    "ds_test = ds_test.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d9183d-249f-4268-a95f-332f2bf60464",
   "metadata": {},
   "source": [
    "## Plot some data samples\n",
    "\n",
    "Plots the MRI and Tumor Masks from a few data samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185ccea2-56cd-47fd-937e-07b435bc3c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(ds, slice_num=None):\n",
    "    \"\"\"\n",
    "    Plot images from dataset\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    plt.figure(figsize=(15,30))\n",
    "    \n",
    "    num_cols=2\n",
    "    \n",
    "    msk_channel=0\n",
    "    img_channel=0 \n",
    "    \n",
    "    for img, msk in ds.take(1):\n",
    "        batch_size = img.shape[0]\n",
    "        if slice_num == None:\n",
    "            slice_num = int(img.shape[3] / 2)\n",
    "\n",
    "        for idx in range(batch_size):\n",
    "            plt.subplot(batch_size, num_cols, idx*num_cols + 1)\n",
    "            plt.imshow(img[idx, :, :, slice_num, img_channel], cmap=\"gray\")\n",
    "            plt.title(f\"MRI {brats_datafiles.input_channels[str(img_channel)]}\", fontsize=18)\n",
    "            plt.subplot(batch_size, num_cols, idx*num_cols + 2)\n",
    "            plt.imshow(msk[idx, :, :, slice_num, msk_channel], cmap=\"gray\")\n",
    "            plt.title(\"Tumor\", fontsize=18)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Mean pixel value of image = {np.mean(img[0,:,:,:,0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06744b98-677c-4b95-ada4-1f92c335c5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plot_images(ds_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a244ad93-430b-4756-9eae-de8e2608cb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plot_images(ds_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef80939-a510-4c05-831f-5908e5ecb050",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plot_images(ds_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
