{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb3b4922-4bf4-4f45-b54e-5bc77b8b4a86",
   "metadata": {},
   "source": [
    "## Convert the TensorFlow 3D UNet model with OpenVINO Model Optimizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268f218d-d481-46a4-acae-2a3674e21750",
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo $CONDA_PREFIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfef80d6-805a-4fac-bfff-471024a9d3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b555da25-da8d-47de-b061-09d741b027b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install openvino-dev[tensorflow2] # Recommend installing from the terminal, but not sure if that works with kernel environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5039f8-9e7e-4e99-b604-038d1ae1af67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!mo -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defa4bbb-b460-4908-b9c8-b59b828299fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import Markdown\n",
    "from openvino.runtime import Core\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras as K\n",
    "\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "    \n",
    "#import warnings\n",
    "#warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867398b4-1f9e-44cc-aee5-7690942457d8",
   "metadata": {},
   "source": [
    "## Define the settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2559569-2245-474b-ac4e-2a231edcba9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"/home/ubuntu/unet/data/\"\n",
    "DATASET = \"Task01_BrainTumour/\"\n",
    "\n",
    "DATA_PATH = \"/home/ubuntu/unet/data/Task01_BrainTumour/\"\n",
    "\n",
    "TRAIN_TEST_SPLIT = 0.80\n",
    "VALIDATE_TEST_SPLIT = 0.50\n",
    "\n",
    "BATCH_SIZE_TRAIN = 8\n",
    "BATCH_SIZE_VALIDATE = 4\n",
    "BATCH_SIZE_TEST = 1\n",
    "\n",
    "TILE_HEIGHT = 144\n",
    "TILE_WIDTH = 144\n",
    "TILE_DEPTH = 144\n",
    "NUMBER_INPUT_CHANNELS = 1\n",
    "\n",
    "#CROP_DIM = (128,128,128,1)\n",
    "\n",
    "NUMBER_OUTPUT_CLASSES = 1\n",
    "\n",
    "\n",
    "MODEL_DIR = Path(\"/home/ubuntu/unet/3D/models\")\n",
    "\n",
    "SAVED_MODEL_NAME = \"3d_unet_decathlon\"\n",
    "\n",
    "FILTERS = 16\n",
    "NUM_EPOCHS=40\n",
    "\n",
    "RANDOM_SEED = 64\n",
    "\n",
    "\n",
    "OUTPUT_DIR = Path(\"/home/ubuntu/unet/3D/models/openvino\")\n",
    "IR_MODEL_PRECISION = \"FP32\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aee5c45-8ed9-4ee9-be3d-9b422b67ff4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The path to the dataset\n",
    "DATA_PATH = Path(Path(DATA_DIR) / DATASET)\n",
    "print(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ec7618-2245-467b-8262-856966889b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The paths of the source and converted models\n",
    "saved_model_path = Path(MODEL_DIR / SAVED_MODEL_NAME)\n",
    "fp32_h5_path = Path(MODEL_DIR / SAVED_MODEL_NAME / SAVED_MODEL_NAME).with_suffix(\".h5\")\n",
    "\n",
    "# Path of optimized TF model using OpenVINO Model Optimizer with FP32 precision\n",
    "fp32_ir_name = Path(SAVED_MODEL_NAME + \"_\" + \"tf\" + \"_\" + \"ov\" + \"_\" + \"fp32\" + \"_ir\")\n",
    "fp32_ir_path = Path(OUTPUT_DIR / fp32_ir_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e258d76e-e01f-4070-94f5-3c6ab95f4524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the command for Model Optimizer\n",
    "mo_command = f\"\"\"mo\n",
    "                 --saved_model_dir \"{saved_model_path}_epoch_37\"\n",
    "                 --input_shape \"[1,{TILE_HEIGHT},{TILE_WIDTH},{TILE_DEPTH},{NUMBER_INPUT_CHANNELS}]\"\n",
    "                 --data_type \"{IR_MODEL_PRECISION}\"\n",
    "                 --output_dir \"{OUTPUT_DIR}\"\n",
    "                 --model_name \"{fp32_ir_name}\"\n",
    "                 \"\"\"\n",
    "mo_command = \" \".join(mo_command.split())\n",
    "print(\"Model Optimizer command to convert TensorFlow to OpenVINO:\")\n",
    "print(mo_command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42db4322-c8e0-4bc9-b27f-9774ba6c8500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the Model Optimizer (overwrites the older model)\n",
    "print(\"Exporting TensorFlow model to IR... This may take a few minutes.\")\n",
    "mo_result = %sx $mo_command\n",
    "print(\"\\n\".join(mo_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fe5368-5094-40f4-b689-5ccd2cde59d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Run Model Optimizer if the IR model file does not exist\n",
    "# if not ir_path.exists():\n",
    "#     print(\"Exporting TensorFlow model to IR... This may take a few minutes.\")\n",
    "#     ! $mo_command\n",
    "# else:\n",
    "#     print(f\"IR model {ir_path} already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1095bced-4260-473d-98b5-c4298191a069",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define a data loader\n",
    "\n",
    "We'll use `tf.data` to define a way to load the BraTS dataset at runtime whenever a new batch of 3D images and masks are requested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2869e374-d738-4ccf-b281-c8704d5205c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloader import DatasetGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356de132-3520-4a07-a98e-622dcf0274fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "brats_datafiles = DatasetGenerator(data_path=DATA_PATH, \n",
    "                                   train_test_split=TRAIN_TEST_SPLIT,\n",
    "                                   validate_test_split=VALIDATE_TEST_SPLIT,\n",
    "                                   batch_size_train=BATCH_SIZE_TRAIN,\n",
    "                                   batch_size_validate=BATCH_SIZE_VALIDATE,\n",
    "                                   batch_size_test=BATCH_SIZE_TEST,\n",
    "                                   tile_height=TILE_HEIGHT, \n",
    "                                   tile_width=TILE_WIDTH, \n",
    "                                   tile_depth=TILE_DEPTH, \n",
    "                                   number_input_channels=NUMBER_INPUT_CHANNELS,\n",
    "                                   number_output_classes=NUMBER_OUTPUT_CLASSES,\n",
    "                                   random_seed=RANDOM_SEED)\n",
    "brats_datafiles.print_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a2705d-ce4a-46de-94ba-5ce857fd4268",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot some data samples\n",
    "\n",
    "Plots the MRI and Tumor Masks from a few data samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f85ab75-bfa8-467c-93a9-2424c741b912",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "brats_datafiles.display_test_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21927e9-e5f6-4caf-b6a6-42ee4834c69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_xml_file = f\"{fp32_ir_path}.xml\"\n",
    "path_to_bin_file = f\"{fp32_ir_path}.bin\"\n",
    "\n",
    "ie = Core()\n",
    "model = ie.read_model(model=path_to_xml_file, weights=path_to_bin_file)\n",
    "compiled_model = ie.compile_model(model=model, device_name=\"CPU\")\n",
    "\n",
    "del model\n",
    "\n",
    "input_layer = next(iter(compiled_model.inputs))\n",
    "output_layer = next(iter(compiled_model.outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd93eb1-f9ea-45d3-a1d5-075b4d252f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import dice_coef, soft_dice_coef, dice_loss\n",
    "tf_model = tf.keras.models.load_model(fp32_h5_path, \n",
    "                                      compile=True, \n",
    "                                      custom_objects={\"dice_coef\":dice_coef, \"soft_dice_coef\":soft_dice_coef, \"dice_loss\":dice_loss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbff882-eb3f-45ed-af34-45221a0bf114",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(img_batch, msk_batch):\n",
    "    #create a dictionary to store the results of all inferences\n",
    "    data = {'img': [], \n",
    "            'msk': [], \n",
    "            'prediction_ov': [], \n",
    "            'dice_coef_ov': [],\n",
    "            'inference_time_ov': [],\n",
    "            'prediction_tf': [], \n",
    "            'dice_coef_tf': [],\n",
    "            'inference_time_tf': []\n",
    "           }\n",
    "\n",
    "    for i in range(img_batch.shape[0]):\n",
    "        img = img_batch[i:i+1,:,:,:,:]\n",
    "        msk = msk_batch[i:i+1,:,:,:,:]    \n",
    "    \n",
    "        slicenum=np.argmax(np.sum(msk, axis=(1,2)))  # Find the slice with the largest tumor section\n",
    "\n",
    "        plt.figure(figsize=(20,20))\n",
    "\n",
    "        plt.subplot(1,4,1)\n",
    "        plt.title(\"MRI\", fontsize=20)\n",
    "        plt.imshow(img[0,:,:,slicenum,0], cmap=\"gray\")\n",
    "        plt.subplot(1,4,2)\n",
    "        plt.imshow(msk[0,:,:,slicenum,0], cmap=\"gray\")\n",
    "        plt.title(\"Ground truth\", fontsize=20)\n",
    "\n",
    "        \n",
    "        \"\"\"\n",
    "        TensorFlow Model Prediction\n",
    "        \"\"\"\n",
    "        start_time = time.time()\n",
    "        prediction_tf = tf_model.predict(img)\n",
    "        inference_time_tf = 1000.0*(time.time()-start_time)\n",
    "        prediction_tf = tf.round(prediction_tf)\n",
    "        dice_coef_tf = dice_coef(msk,prediction_tf)\n",
    "\n",
    "        plt.subplot(1,4,3)\n",
    "        plt.imshow(prediction_tf[0,:,:,slicenum,0], cmap=\"gray\")\n",
    "        plt.title(f\"TensorFlow Prediction\\nFP32\\nDice = {dice_coef_tf:.4f}\\n\\nInference time\\n{inference_time_tf:.4f} msecs\", fontsize=20)\n",
    "\n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "        OpenVINO Model Prediction - FP32\n",
    "        Note: OpenVINO assumes the input (and output) are organized as channels first (NCHWD)\n",
    "        whereas TensorFlow assumes channels last (NHWDC). We'll use the NumPy transpose\n",
    "        to change the order.\n",
    "        \"\"\"\n",
    "        start_time = time.time()\n",
    "        request = compiled_model.create_infer_request()\n",
    "        request.infer(inputs={input_layer.any_name: img})\n",
    "        prediction_ov = request.get_output_tensor(output_layer.index).data\n",
    "        inference_time_ov = 1000.0*(time.time()-start_time)\n",
    "        prediction_ov = tf.round(prediction_ov)\n",
    "        dice_coef_ov = dice_coef(msk,prediction_ov)\n",
    "\n",
    "        plt.subplot(1,4,4)\n",
    "        plt.imshow(prediction_ov[0,:,:,slicenum,0], cmap=\"gray\")\n",
    "        plt.title(f\"OpenVINO Prediction\\nFP32\\nDice = {dice_coef_ov:.4f}\\n\\nInference time\\n{inference_time_ov:.4f} msecs\", fontsize=20)\n",
    "\n",
    "        \n",
    "        import pickle\n",
    "\n",
    "        data['img'].append(img) \n",
    "        data['msk'].append(msk)\n",
    "        data['prediction_ov'].append(prediction_ov) \n",
    "        data['dice_coef_ov'].append(dice_coef_ov)\n",
    "        data['inference_time_ov'].append(inference_time_ov)\n",
    "        data['prediction_tf'].append(prediction_tf) \n",
    "        data['dice_coef_tf'].append(dice_coef_tf)\n",
    "        data['inference_time_tf'].append(inference_time_tf)\n",
    "\n",
    "        prediction_results_path = Path(Path(DATA_DIR) / \"prediction_results.pkl\")\n",
    "        with open(prediction_results_path, 'wb') as outfile:\n",
    "            pickle.dump(data, outfile, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b819bfd4-bd60-4ad8-9143-157fd61f500e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_predictions(img_batch, msk_batch):\n",
    "#     for i in range(img_batch.shape[0]):\n",
    "#         img = img_batch[i:i+1,:,:,:,:]\n",
    "#         msk = msk_batch[i:i+1,:,:,:,:]    \n",
    "    \n",
    "#         slicenum=np.argmax(np.sum(msk, axis=(1,2)))  # Find the slice with the largest tumor section\n",
    "\n",
    "#         plt.figure(figsize=(20,20))\n",
    "\n",
    "#         plt.subplot(1,4,1)\n",
    "#         plt.title(\"MRI\", fontsize=20)\n",
    "#         plt.imshow(img[0,:,:,slicenum,0], cmap=\"gray\")\n",
    "#         plt.subplot(1,4,2)\n",
    "#         plt.imshow(msk[0,:,:,slicenum,0], cmap=\"gray\")\n",
    "#         plt.title(\"Ground truth\", fontsize=20)\n",
    "\n",
    "        \n",
    "#         \"\"\"\n",
    "#         TensorFlow Model Prediction\n",
    "#         \"\"\"\n",
    "#         start_time = time.time()\n",
    "#         prediction_tf = tf_model.predict(img)\n",
    "#         inference_time_tf = 1000.0*(time.time()-start_time)\n",
    "#         prediction_tf = tf.round(prediction_tf)\n",
    "#         dice_coef_tf = dice_coef(msk,prediction_tf)\n",
    "\n",
    "#         plt.subplot(1,4,3)\n",
    "#         plt.imshow(prediction_tf[0,:,:,slicenum,0], cmap=\"gray\")\n",
    "#         plt.title(f\"TensorFlow Prediction\\nFP32\\nDice = {dice_coef_tf:.4f}\\n\\nInference time\\n{inference_time_tf:.4f} msecs\", fontsize=20)\n",
    "\n",
    "        \n",
    "        \n",
    "#         \"\"\"\n",
    "#         OpenVINO Model Prediction - FP32\n",
    "#         Note: OpenVINO assumes the input (and output) are organized as channels first (NCHWD)\n",
    "#         whereas TensorFlow assumes channels last (NHWDC). We'll use the NumPy transpose\n",
    "#         to change the order.\n",
    "#         \"\"\"\n",
    "#         start_time = time.time()\n",
    "#         request = compiled_model.create_infer_request()\n",
    "#         request.infer(inputs={input_layer.any_name: img})\n",
    "#         prediction_ov = request.get_output_tensor(output_layer.index).data\n",
    "#         inference_time_ov = 1000.0*(time.time()-start_time)\n",
    "#         prediction_ov = tf.round(prediction_ov)\n",
    "#         dice_coef_ov = dice_coef(msk,prediction_ov)\n",
    "\n",
    "#         plt.subplot(1,4,4)\n",
    "#         plt.imshow(prediction_ov[0,:,:,slicenum,0], cmap=\"gray\")\n",
    "#         plt.title(f\"OpenVINO Prediction\\nFP32\\nDice = {dice_coef_ov:.4f}\\n\\nInference time\\n{inference_time_ov:.4f} msecs\", fontsize=20)\n",
    "\n",
    "        \n",
    "#         import pickle\n",
    "\n",
    "#         data = {'img': img, \n",
    "#                 'msk': msk, \n",
    "#                 'prediction_ov': prediction_ov, \n",
    "#                 'dice_coef_ov': dice_coef_ov,\n",
    "#                 'inference_time_ov': inference_time_ov,\n",
    "#                 'prediction_tf': prediction_tf, \n",
    "#                 'dice_coef_tf': dice_coef_tf,\n",
    "#                 'inference_time_tf': inference_time_tf\n",
    "#                }\n",
    "#         prediction_results_path = Path(DATA_DIR / \"prediction_results.pkl\")\n",
    "#         with open(prediction_results_path, 'wb') as outfile:\n",
    "#             pickle.dump(data, outfile, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a98047-d86d-467b-8732-d9430abd0d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "ds = brats_datafiles.get_train().take(1).as_numpy_iterator()\n",
    "for img, msk in ds:\n",
    "    plot_predictions(img,msk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3a6a6a-5f85-42b5-90cf-7664701bc547",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab0565b-d85b-447d-aa92-99993d81873a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673ae4f1-a469-46e6-9a74-4f265bc6412c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fac748-38cc-44a3-95fd-360fb7a7b8bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b725d837-7dba-46ca-b02a-b4c231c5c489",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c5c32b-c7c5-4f63-99e3-97efaadc626a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285ffa46-b08c-4f31-adfd-b2c72ee450be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2fa357-5af5-49a6-8963-d56019dde2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import AppLayout, IntSlider, Layout, VBox\n",
    "import ipywidgets as widgets\n",
    "\n",
    "\n",
    "def plot_interactive_predictions(img, msk, channel=0):\n",
    "    img = img[:, :, :, :, channel:channel+1]\n",
    "    max_img = img.shape[3]\n",
    "    print(max_img)\n",
    "    mid_img = int(max_img / 2)\n",
    "    print(mid_img)\n",
    "    \n",
    "    \"\"\"\n",
    "    OpenVINO Model Prediction\n",
    "    Note: OpenVINO assumes the input (and output) are organized as channels first (NCHWD)\n",
    "    whereas TensorFlow assumes channels last (NHWDC). We'll use the NumPy transpose\n",
    "    to change the order.\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    request = compiled_model.create_infer_request()\n",
    "    request.infer(inputs={input_layer.any_name: img})\n",
    "    prediction_ov = request.get_output_tensor(output_layer.index).data\n",
    "    dice_coef_ov = calc_dice(msk,prediction_ov)\n",
    "    print(\"OpenVINO inference time = {:.4f} msecs\".format(1000.0*(time.time()-start_time)))\n",
    "    \n",
    "    \"\"\"\n",
    "    TensorFlow Model Prediction\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    prediction_tf = tf_model.predict(img)\n",
    "    dice_coef_tf = calc_dice(msk,prediction_tf)\n",
    "    print(\"TensorFlow inference time = {:.4f} msecs\".format(1000.0*(time.time()-start_time)))\n",
    "    \n",
    "    \n",
    "    plt.ioff()\n",
    "    fig, ax = plt.subplots(1,1, figsize=(8,8))\n",
    "    plt.ion()\n",
    "\n",
    "   \n",
    "#    ax[0].title(\"MRI\", fontsize=20) #row=0, col=0\n",
    "    im = ax.imshow(img[0,:,:,mid_img,0], cmap=\"gray\")\n",
    "#    ax[1].title(\"Ground Truth\", fontsize=20) #row=1, col=0\n",
    "#    lbl = ax[1].imshow(msk[0,:,:,mid_img,0], cmap=\"gray\")\n",
    "#    ax[2].title(\"OpenVINO Prediction\\nDice = {:.4f}\".format(dice_coef_ov), fontsize=20)\n",
    "#    ovp = ax[2].imshow(prediction_ov[0,:,:,mid_img,0], cmap=\"gray\")\n",
    "#    ax[3].title(\"TensorFlow Prediction\\nDice = {:.4f}\".format(dice_coef_tf), fontsize=20) #row=1, col=1\n",
    "#    tfp = ax[3].imshow(prediction_tf[0,:,:,mid_img,0], cmap=\"gray\")\n",
    "    \n",
    "    \n",
    "    fig.canvas.header_visible = False\n",
    "    #fig.canvas.layout.min_height = '400px'\n",
    "    fig.canvas.toolbar_visible = False\n",
    "    plt.title('Axial View Slice n.')\n",
    "    \n",
    "    def update(change):\n",
    "        im.set_data(img[0, :, :, change['new'],0], cmap=\"gray\")\n",
    "#        lbl.set_data(msk[0, :, :, change['new'],0], cmap=\"gray\")\n",
    "#        ovp.set_data(prediction_ov[0, :, :, change['new'],0], cmap=\"gray\")\n",
    "#        tfp.set_data(prediction_tf[0, :, :, change['new'],0], cmap=\"gray\")\n",
    "        fig.canvas.draw_idle()\n",
    "\n",
    "        \n",
    "    slider = widgets.IntSlider(orientation='horizontal', \\\n",
    "        description='Slice #:', value=mid_img, min=0, max=max_img)\n",
    "\n",
    "    slider.layout.margin = '0px 0px 0px 0px'\n",
    "    #slider.layout.margin = '20% 0px 20% 0px'\n",
    "    slider.layout.width = '80%'\n",
    "    \n",
    "    slider.observe(update, names='value')\n",
    "    \n",
    "    \n",
    "    viewer = VBox([slider, fig.canvas], layout=Layout(align_items='center'))\n",
    "\n",
    "    #widgets.VBox([slider, fig.canvas])\n",
    "    # viewer = AppLayout(\n",
    "    #     center=fig.canvas,\n",
    "    #     left_sidebar=slider,\n",
    "    #     right_sidebar=None,\n",
    "    #     pane_widths=[1, 8, 0]\n",
    "    # )\n",
    "    return viewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff43e18-dedc-45f4-afac-a82b3184cbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "ds = ds_train.take(1).as_numpy_iterator()\n",
    "#print(ds.shape)\n",
    "for img, msk in ds:\n",
    "    img, msk = img, msk\n",
    "viewer = plot_interactive_predictions(img,msk)\n",
    "display(viewer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa47cea5-66cb-43b1-9be8-6901d47249da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77b8d14-be45-46fe-92ec-fec380d9fd0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41007cd7-b714-4c3b-a31f-7ca5dcfb75b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba550268-f7ac-4278-bfbe-d9f8f82384b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bz_perf = 1\n",
    "ds_perf = ds_train.batch(bz_perf)\n",
    "ds_perf = ds_train.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14b7e8e-4d93-4323-93df-9325c3fca97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "takes = 100\n",
    "ds_perf_test = ds_perf.take(takes).as_numpy_iterator()\n",
    "\n",
    "num_images = takes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78b8360-b751-416f-a3b2-c13d6ded624c",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.perf_counter()\n",
    "counter = 0\n",
    "\n",
    "request = compiled_model.create_infer_request()\n",
    "for img, _ in ds_perf_test:\n",
    "    request.infer(inputs={input_layer.any_name: img})\n",
    "    #start_time = time.time()\n",
    "    request.infer(inputs={input_layer.any_name: img})\n",
    "    prediction_ov = request.get_output_tensor(output_layer.index).data\n",
    "    dice_coef_ov = calc_dice(msk,prediction_ov)\n",
    "    counter += 1\n",
    "    \n",
    "    #print(\"OpenVINO inference time = {:.4f} msecs\".format(1000.0*(time.time()-start_time)))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "end = time.perf_counter()\n",
    "time_ir = end - start\n",
    "print(counter)\n",
    "print(\n",
    "    f\"IR model in Inference Engine/CPU: {time_ir/num_images:.4f} \"\n",
    "    f\"seconds per image, FPS: {num_images/time_ir:.2f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a693ad-4591-4bdf-9dd1-6c5f602d854b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
